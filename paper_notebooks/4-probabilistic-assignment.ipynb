{
 "cells": [{
   "cell_type": "code",
   "execution_count": null,
   "id": "51571a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import siibra\n",
    "assert siibra.__version__ == \"2.0.0.a01\"\n",
    "import numpy as np\n",
    "from nilearn import plotting, image\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "import pandas as pd\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a64df9b",
   "metadata": {},
   "source": [
    "# Input: some feature  distribution in MNI space \n",
    "\n",
    "We compose an artificial input image by merging some functional maps from the DiFuMo atlas, but this could be anything, e.g. an fMRI activation map. The image is built as a NIfTI, but then casted to a siibra volume so we have a reference space attached and can used it properly in the siibra workflows. Getting the NIfTI object from the siibra volume is cheap and easy via `.fetch()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab3ef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "difumo64 = siibra.get_map(parcellation=\"difumo 64\", space='mni 152', maptype='statistical')\n",
    "img = image.smooth_img(image.math_img(\n",
    "        \"np.maximum(np.maximum(im1, im2), im3)\", \n",
    "        im1=difumo64.extract_regional_map(region=\"3\").get_data(), \n",
    "        im2=difumo64.extract_regional_map(region=\"31\").get_data(),\n",
    "        im3=difumo64.extract_regional_map(region=\"39\").get_data(), \n",
    "    ), 10)\n",
    "\n",
    "# we cast the nifti object to a siibra volume, so it has a space attached and can be used properly\n",
    "input_provider = siibra.factory.imageprovider_from_nifti(img, space='mni 152')\n",
    "plotting.plot_glass_brain(input_provider.get_data(), alpha=1, cmap='RdBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caedfb4c",
   "metadata": {},
   "source": [
    "# Split input volume into cluster components\n",
    "\n",
    "There are many ways to get components out of a feature map. Here we use siibra to \n",
    "\n",
    "- draw random points from the distribution encoded by the input volume, then \n",
    "- cluster them using DBSCAN, and \n",
    "- build clusterwise featuremaps as Kernel Density estimates thereof.\n",
    "\n",
    "In this example, this more or less inverts the composition of the input volume from the DiFuMo maps, but the idea for a general input image is to separate it into components that have more meaningful correlations with brain regions than the full image, which is usually a mixture distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52489eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=27)\n",
    "N = 10000  # number of random samples\n",
    "# drawing the samples results in a siibra PointSet, \n",
    "# which has reference space attached and can model point uncertainties.\n",
    "samples = siibra.factory.pointcloud_sampled_from_image(input_provider, N, e=5, sigma=3)\n",
    "\n",
    "# finding the clusters will result in a labelling of the point set.\n",
    "clusters = samples.find_clusters(min_fraction=1/300, max_fraction=1/2)\n",
    "clusterlabels = set(clusters.labels) - {-1}\n",
    "\n",
    "# Let's have a look at the clustered pointcloud\n",
    "\n",
    "cmap = cm.rainbow(np.linspace(0, 1, max(clusters.labels) + 1))\n",
    "view = plotting.plot_glass_brain(input_provider.get_data(), alpha=1, threshold=15, cmap='RdGy')\n",
    "view.add_markers(\n",
    "    np.array(clusters.coordinates)[np.array(clusters.labels) >= 0],\n",
    "    marker_size=5,\n",
    "    marker_color=[cmap[l] for l in clusters.labels if l >= 0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7877a7",
   "metadata": {},
   "source": [
    "# Assign peaks and clusters to cytoarchitectonic regions\n",
    "\n",
    "To assign the clusters to brain regions, we build feature maps from each cluster and assign them to the Julich-Brain probabilistic maps. The assignemint is one-to-many since the structures in the image and parcellation are continuous. Assignments report correlation, intersection over union, and some other measures which we can use to filter and sort them.\n",
    "\n",
    "The result is an assignment table from cluster components in the input volume to regions in the Julich-Brain atlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "751004e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_correlation = 0.3\n",
    "min_map_value = 0.5\n",
    "pmaps = siibra.get_map(parcellation=\"julich 3.1\", space=\"mni 152\", maptype='statistical', name='207')\n",
    "assignments = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c1f25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign peaks to regions\n",
    "peaks = siibra.factory.pointcloud_from_image_peaks(input_provider, mindist=5, sigma=0)\n",
    "df = pmaps.assign(peaks)\n",
    "df.query(f\"`map_value` >= {min_map_value}\", engine='python', inplace=True)\n",
    "df['type'] = 'peak'\n",
    "df['id'] = df['input_structure_index']   \n",
    "assignments.append(df[['type', 'id', 'regionname', 'map_value']])\n",
    "\n",
    "view = plotting.plot_glass_brain(input_provider.get_data(), alpha=1, cmap='RdBu')\n",
    "view.add_markers(peaks.coordinates, marker_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f34c5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign clusters to regions\n",
    "for l in clusterlabels:\n",
    "    print(f\"cluster {l}\")\n",
    "    clustermap_provider = siibra.factory.imageprovider_from_pointcloud(\n",
    "        clusters.filter_by_label([l]), target=input_provider\n",
    "    )\n",
    "    plotting.plot_glass_brain(\n",
    "        clustermap_provider.get_data(), alpha=1, cmap=\"RdBu\", title=f\"Cluster #{l}\"\n",
    "    )\n",
    "    df = pmaps.assign(clustermap_provider)\n",
    "    df.query(f\"correlation >= {min_correlation}\", engine=\"python\", inplace=True)\n",
    "    df[\"type\"] = \"cluster\"\n",
    "    df[\"id\"] = l\n",
    "    assignments.append(\n",
    "        df[[\"type\", \"id\", \"regionname\", \"correlation\", \"map_value_mean\"]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df8c0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_assignments = pd.concat(assignments).sort_values(by='map_value_mean', ascending=False)\n",
    "all_assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6f1d69",
   "metadata": {},
   "source": [
    "# Find features\n",
    "\n",
    "To demonstrate multimodal feateure profiling, we only choose the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374b0631",
   "metadata": {},
   "outputs": [],
   "source": [
    "regionname = all_assignments.iloc[0][\"regionname\"]\n",
    "pmap = pmaps.extract_regional_map(regionname)\n",
    "plotting.plot_stat_map(pmap.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16acac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = pmaps.get_region(regionname) \n",
    "profiling = [\n",
    "    [siibra.modality_vocab.modality.NEUROTRANSMITTER_RECEPTOR_DENSITY, {}],\n",
    "    [siibra.modality_vocab.modality.CELL_BODY_DENSITY, {}],\n",
    "    # [siibra.modality_vocab.modality.STREAMLINECOUNTS, {}],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d303d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(profiling), 1, figsize=(6.0, 2.5 * len(profiling)))\n",
    "\n",
    "for i, (modality, kwargs) in enumerate(profiling):\n",
    "    features = siibra.find_features(region, modality, **kwargs)\n",
    "    features[0].plot(ax=axs[i])\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183b63ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "region = siibra.get_region('3.0.3', region.name)\n",
    "features = siibra.find_features(region, siibra.modality_vocab.modality.STREAMLINECOUNTS)\n",
    "\n",
    "ft = features[0]\n",
    "\n",
    "def shortname(name):\n",
    "    return (\n",
    "        re.sub('\\s*\\(.*\\)\\s*|\\s*Area\\s*', ' ', name)\n",
    "        .replace('left', 'L')\n",
    "        .replace(\"hemisphere\", \"\")\n",
    "        .replace('right', 'R')\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "\n",
    "dp = ft.get_datarecipe(\"name == 'Subject: 000'\")\n",
    "df = dp.get_data()\n",
    "profile = df[region.name]\n",
    "sorted_series = profile.sort_values(ascending=False)\n",
    "named_sorted_series = sorted_series.rename(index={r:shortname(r) for r in sorted_series.index})\n",
    "named_sorted_series[:15].plot(kind=\"bar\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}