{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting image data at possibly high resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import siibra\n",
    "from nilearn import plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro: Spaces and Parcellations, Reference templates and maps, and their image data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`siibra` uses different layers of abstraction. On the top level, we have semantic concepts: atlases, spaces, parcellations. They are pure semantical objects, they do not contain any actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigbrainspace = siibra.spaces.BIG_BRAIN\n",
    "cortexparcellation = siibra.parcellations['cortex']\n",
    "type(bigbrainspace),type(cortexparcellation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The semantic objects can construct image objects. For example, a space can construct a template image, and a parcellation can construct parcellation maps in a particular space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigbrain_template = bigbrainspace.get_template()\n",
    "cortex_map = cortexparcellation.get_map(bigbrainspace)\n",
    "type(bigbrain_template), type(cortex_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, none of those has loaded image data yet. `siibra` follows a lazy scheme of loading image data. To get access to actual images, we apply the `fetch` method, which has an optional parameter for the physcial resolution. `fetch` returns nibabel image objects with an affine matrix pointing to the physical space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_img = bigbrain_template.fetch(resolution_mm=0.64)\n",
    "cortex_img =  cortex_map.fetch(resolution_mm=0.8)\n",
    "type(template_img), type(cortex_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can easily visualize those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotmap(img,tpl,opacity=1.):\n",
    "    return plotting.view_img(\n",
    "        img,\n",
    "        bg_img=tpl,\n",
    "        symmetric_cmap=False,\n",
    "        resampling_interpolation='nearest',\n",
    "        opacity=opacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotmap(cortex_img,template_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using an atlas to access spaces and parcellations\n",
    "\n",
    "The `siibra` atlas object facilitates this process a bit, by bringing spaces and parcellations into one context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "atlas = siibra.atlases['human']\n",
    "atlas.select(parcellation=\"cortex\")\n",
    "template_img = atlas.get_template(\"bigbrain\").fetch(resolution_mm=0.64)\n",
    "cortex_img = atlas.get_map(\"bigbrain\").fetch(resolution_mm=0.8)\n",
    "plotmap(cortex_img,template_img,opacity=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting a volume of interest at full resolution\n",
    "\n",
    "We specify the rectangular volume of interest with two 3D points (the min and max point)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minpt = (-3.979, -61.256, 3.906)\n",
    "maxpt = (5.863, -55.356, -2.487)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A volume of interest is always defined in a particular space. Here, we define it in BigBrain space of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voi = bigbrain.get_voi(minpt,maxpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can extract a chunk from the BigBrain template a full resolution of 20 micron using this volume of interest specification. The extracted chunk sits nicely in BigBrain space. We can plot it in context, although it is extracted at a very different resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigbrainchunk = bigbrain.get_template().fetch(resolution_mm=0.02,voi=voi)\n",
    "plotting.view_img(bigbrainchunk,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reapply the volume of interest specification to extract chunks from other objects in this space as well, like parcellation maps. Here we use the cortex map of BigBrain, passing the specification to the fetch() method of the map. We can then plot it with the full-resolution chunk as template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cortexmap = siibra.parcellations['isocortex'].get_map(\"bigbrain\")\n",
    "mask = cortexmap.fetch(resolution_mm=0.2,voi=voi)\n",
    "plotmap(mask,chunk,opacity=.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
