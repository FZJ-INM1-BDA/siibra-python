{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing maps and template data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import siibra\n",
    "from nilearn import plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro: Semantic concepts, spatial objects, and image data\n",
    "\n",
    "The main concepts in `siibra` are modelled in three levels: Semantic concepts, spatial concepts, and concrete (often image) data.\n",
    "\n",
    "#### 1. Semantic concepts: Atlases, reference spaces and brain parcellations\n",
    "\n",
    "On the top level, we have classes modeling the semantic concepts: atlases, reference spaces, brain parcellations. Objects of these classes do not include actual image or other data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mni152space = siibra.spaces.MNI152_2009C_NONL_ASYM\n",
    "# works as well: siibra.spaces['mni152']\n",
    "julichbrain = siibra.parcellations.JULICH_BRAIN_CYTOARCHITECTONIC_MAPS_2_9\n",
    "# works as well: siibra.parcellations['julich']\n",
    "type(mni152space),type(julichbrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spaces and parcellations typically refer to entities in the EBRAINS knowledge graph, modelled in the MINDS and openMINDS standards. `siibra` stores their identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mni152space.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parcellation objects define hierarchical regiontrees, and allow to search brain regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "julichbrain.find_regions('lateral occipital')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Spatial concepts: reference templates, parcellation maps\n",
    "\n",
    "Reference spaces and parcellations have spatial representations in specific coordinate systems. For example, a space provides a reference template, and a parcellation provides parcellation maps of possibly different type in different reference spaces. Spatial objects are obtained from semantic objects by specifying a space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jub_maxpm = julichbrain.get_map(mni152space,maptype=siibra.MapType.LABELLED)\n",
    "# works also: jub_maxpm = julichbrain.get_map(\"mni152\",maptype=\"labelled\")\n",
    "jub_pmaps = julichbrain.get_map(mni152space,maptype=siibra.MapType.CONTINUOUS)\n",
    "type(jub_maxpm), type(jub_pmaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Image data: Template images, labelled maps, probabilistic maps, volumes of interest\n",
    "\n",
    "`siibra` follows a lazy scheme of loading image data, because some of the unerlying data is large. To get access to actual image data, we apply the `fetch` method of spatial objects, which allows optional specification of resolution and regions of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_stat_map(jub_maxpm.fetch())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same for the Colin27 space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colin = siibra.spaces['colin'].get_template().fetch()\n",
    "colin_mpm = siibra.parcellations['julich'].get_map('colin').fetch()\n",
    "plotting.plot_stat_map(colin_mpm,bg_img=colin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can also retrieve BigBrain template and maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigbrainspace = siibra.spaces.BIG_BRAIN\n",
    "bigbraintemplate = bigbrainspace.get_template()\n",
    "\n",
    "layerparcellation = siibra.parcellations['cortical layers']\n",
    "layermap = layerparcellation.get_map(bigbrainspace)\n",
    "\n",
    "# for Bigbrain, we select a coarser resolution, it's too large otherwise\n",
    "img = layermap.fetch(resolution_mm=0.64)\n",
    "tpl = bigbraintemplate.fetch(resolution_mm=0.64)\n",
    "\n",
    "plotting.view_img(img,bg_img=tpl,opacity=.4,symmetric_cmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using an atlas to simplify access to spaces and parcellations\n",
    "\n",
    "The `siibra` atlas class facilitates the work with parcellations and spaces by bringing them into context. The above can be performed in short form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas = siibra.atlases.MULTILEVEL_HUMAN_ATLAS\n",
    "template_img = atlas.get_template(\"bigbrain\").fetch(resolution_mm=0.64)\n",
    "layer_img = atlas.get_map(space=\"bigbrain\",parcellation=\"layers\").fetch(resolution_mm=0.64)\n",
    "plotting.view_img(layer_img,bg_img=template_img,opacity=.5,symmetric_cmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The atlas object allows to select different parcellations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "julichbrain_mpm_left = atlas.get_map(\"mni152\",\"julich-brain\").fetch()\n",
    "plotting.plot_stat_map(julichbrain_mpm_left)\n",
    "# Note: using fetch_all(), we would have obtained both hemispheres\n",
    "    \n",
    "bundles_mpm = atlas.get_map(\"mni152\",\"long bundles\").fetch()\n",
    "plotting.plot_stat_map(bundles_mpm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A similar logic applies to select regions and build region masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve a binary mask of the selected region(s)\n",
    "v1l= atlas.get_region('v1 left')\n",
    "v1_mask_l = v1l.build_mask(\"mni152\")\n",
    "plotting.plot_roi(v1_mask_l)\n",
    "\n",
    "# retrieve a continuous regional map of the selected region, if available\n",
    "v1_pmap_l = v1l.get_regional_map(\"mni152\",\"continuous\")\n",
    "plotting.plot_stat_map(v1_pmap_l.fetch())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting volumes of interest from high-resolution data\n",
    "\n",
    "To access BigBrain Data at higher resolution, we specify a rectangular volume of interest spanned by two 3D points in physical coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minpoint = (-3.979, -61.256, 3.906)\n",
    "maxpt = (5.863, -55.356, -2.487)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The volume of interest definition is requested from the desired space. Here, we use the BigBrain space of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voi = atlas.get_voi('bigbrain',minpoint,maxpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can extract a chunk from the BigBrain template a full resolution of 20 micron using this volume of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigbrainchunk = atlas.get_template('bigbrain').fetch(resolution_mm=0.02,voi=voi)\n",
    "plotting.view_img(bigbrainchunk,None,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting image chunk sits properly in its reference space, so we can also plot it in anatomical context of the low-resolution whole brain model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that we already fetched the template volume above:\n",
    "# tpl=bigbraintemplate.fetch(resolution_mm=0.64)\n",
    "plotting.plot_roi(bigbrainchunk,bg_img=tpl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply this volume of interest to extract chunks from other objects in the same space, like parcellation maps. Here we use the coritcal layer maps of BigBrain. We can use the LabelledParcellation object for the cortical layer maps that we requested further above, but no call its `fetch()` method again with a different resolution and the volume of interest specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = layermap.fetch(resolution_mm=0.08,voi=voi)\n",
    "plotting.view_img(mask,bg_img=bigbrainchunk,opacity=.5,symmetric_cmap=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
