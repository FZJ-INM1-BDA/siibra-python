{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#import matplotlib as mpl\n",
    "#mpl.rcParams['figure.dpi']= 200  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Setup brainscapes\n",
    "\n",
    "### Set a EBRAINS Knowledge Graph access token\n",
    "\n",
    "Brainscapes retrieves some data from the EBRAINS Knowledge Graph, which requires\n",
    "authentication. To do so, please follow these steps:\n",
    "\n",
    " 1. If you do not yet have an EBRAINS account, register [here](https://ebrains.eu/register). As you are reading this notebook in the EBRAINS collaboratory, this is most probably not necessary at this point.\n",
    " 2. Your EBRAINS account needs to be enabled for programmatic access to the EBRAINS Knowledge Graph to fetch metadata. This is formal step to acknowledge additional terms of use, and done quickly by emailing to the KG team. A link and template email to do so can be found right on top of the [Knowledge Graph developer page](https://kg.humanbrainproject.eu/develop.html).\n",
    " 3. Create an authentication token for EBRAINS by visiting\n",
    "[the EBRAINS authorization endpoint](https://nexus-iam.humanbrainproject.org/v0/oauth2/authorize). \n",
    " 4. Copy the token, and store it in the enviroment variable `HBP_AUTH_TOKEN` (just modify and execute the cell below accordingly).\n",
    "\n",
    "Note that as of now, you have to get a new token (steps 3. and 4.) approximately every day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "from os import environ\n",
    "webbrowser.open('https://nexus-iam.humanbrainproject.org/v0/oauth2/authorize')\n",
    "token = input(\"Enter your token here: \")\n",
    "environ['HBP_AUTH_TOKEN'] = token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: adjust local data cache\n",
    "\n",
    "Brainscapes maintains a local cache of retrieved data. It will automatically choose the system default of your user account on most common operating systems, but you an also choose an explicit folder by setting the environment variable `BRAINSCAPES_CACHEDIR`. We are not using this here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir -p /tmp/brainscapescache\n",
    "#environ['BRAINSCAPES_CACHEDIR'] = \"/tmp/brainscapescache\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brainscapes as bs\n",
    "bs.logger.setLevel(\"INFO\") # show us some messages\n",
    "#bs.clear_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Choosing a parcellation\n",
    "\n",
    "We first load and show the previous Julich-Brain version, then the most recent one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas = bs.atlases.MULTILEVEL_HUMAN_ATLAS\n",
    "atlas.select_parcellation(bs.parcellations.JULICH_BRAIN_PROBABILISTIC_CYTOARCHITECTONIC_MAPS_V2_5)\n",
    "\n",
    "# in MNI 152 space\n",
    "icbm_mri = atlas.get_template(bs.spaces.MNI_152_ICBM_2009C_NONLINEAR_ASYMMETRIC)\n",
    "icbm_maps = atlas.get_maps(bs.spaces.MNI_152_ICBM_2009C_NONLINEAR_ASYMMETRIC)\n",
    "plotting.plot_stat_map(icbm_maps['left hemisphere'])\n",
    "\n",
    "# bigbrain\n",
    "bigbrain_template = atlas.get_template(bs.spaces.BIG_BRAIN_HISTOLOGY,resolution=640)\n",
    "bigbrain_map = atlas.get_maps(bs.spaces.BIG_BRAIN_HISTOLOGY,resolution=640)\n",
    "plotting.plot_stat_map(bigbrain_map,bg_img=bigbrain_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting brain regions from an atlas\n",
    "\n",
    "To select atlas regions, an explicit region identifier or unique name and key can be used. If an arbitrary string is passed, the client  does its best to identify the corresponding region. It will complain if that is not possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can just give a string and see if the system can disambiguiate it\n",
    "atlas.select_region(\"v1\")\n",
    "print(\"Selected region from 'v1' is\",atlas.selected_region)\n",
    "\n",
    "print('v1 includes the left and right hemisphere!')\n",
    "print(repr(atlas.selected_region))\n",
    "\n",
    "# we can be more specific easily\n",
    "atlas.select_region(\"v1 left\")\n",
    "print(\"Selected region from 'v1 left' is\",atlas.selected_region)\n",
    "\n",
    "# we can also auto-complete on the 'regionnames' attribute of the atlas \n",
    "# - this immediately leads to a unique selection\n",
    "atlas.select_region(atlas.selected_parcellation.regionnames.AREA_HOC1_V1_17_CALCS_LEFT_HEMISPHERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also search the region hierarchy to explore available regions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_regions = atlas.selected_parcellation.regions.find('ifg')\n",
    "print(\"Regions found for search string 'ifg':\")\n",
    "print(\"\\n\".join(\" - \"+str(r) for r in matching_regions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brainscapes supports access to continuous maps for some parcellations. For the Julich-Brain, this translates to the actual probability maps of each area. Let's look at a probability map of the frontal pole in the ICBM space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas.select_region('fp2 right')\n",
    "pmap = atlas.selected_region.get_specific_map(bs.spaces.MNI_152_ICBM_2009C_NONLINEAR_ASYMMETRIC)\n",
    "plotting.plot_roi(pmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Extracting brain region features from EBRAINS\n",
    "\n",
    "We can run queries from any selected subtree in the region hierarchy, but here we select a particular cortical region from the frontal lobe ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Extract spatial properties of brain regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = atlas.regionprops(\n",
    "    bs.spaces.MNI_152_ICBM_2009C_NONLINEAR_ASYMMETRIC)\n",
    "for prop in props:\n",
    "    print(prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract transmitter receptor densities\n",
    "\n",
    "Transmitter receptor density fingerprints are linked to brain regions by their name in the EBRAINS Knowledge Graph. Like any data feature, they are accessed using the `query_data` method of the atlas, which makes use of the current selection in the atlas. The `query_data` method knows from the specified data modality that the match is determined from the brain region identified. Receptor densities come as a nicely structured datatype. Amongst other things, they can visualize themselves in a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas.select_region('v1 left')\n",
    "features = atlas.query_data(\n",
    "    bs.features.modalities.ReceptorDistribution)\n",
    "for r in features:\n",
    "    fig = r.plot(r.region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Extracting Gene Expressions from the Allen Atlas \n",
    "\n",
    "The atlas client can make calls to gene expression data from the Allen atlas and evaluate them in the ICBM space to find regional gene expression levels. It also has a list of available gene names for convenient selection. Gene expressions are linked to atlas regions by coordinates of their probes in MNI space. The `query_data` method detects this from the feature modality, and applies the mask of the regions that are currently selected in the atlas to filter the probes. We can visualize these filtered locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = atlas.query_data(\n",
    "    bs.features.modalities.GeneExpression, \n",
    "    gene=bs.features.gene_names.GABARAPL2)\n",
    "print(features[0])\n",
    "\n",
    "# plot\n",
    "all_coords = [tuple(g.location) for g in features]\n",
    "mask = atlas.get_mask(bs.spaces.MNI_152_ICBM_2009C_NONLINEAR_ASYMMETRIC)\n",
    "display = plotting.plot_roi(mask)\n",
    "display.add_markers(all_coords,marker_size=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Retrieving a connectivity matrix\n",
    "For brainscapes, a connectivity matrix is a data feature like the others below, and can be found using the same `query_data` function just by choosing another modality. Brainscapes knows from the modality type that this type of data does not match to the selected brain region in the atlas, but to the selected parcellation. Therefore, `query_data` return connectivity datasets that are defined for the selected parcellation. \n",
    "\n",
    "To learn about the nature of the provided connectivity, the `src_info` attribute provides a detailed description of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first four connectivity matrices available for the parcellation\n",
    "features = atlas.query_data(bs.features.modalities.ConnectivityMatrix)[:4]\n",
    "\n",
    "# format dataset names for use as figure titles\n",
    "from textwrap import wrap\n",
    "titleformat = lambda text : \"\\n\".join(wrap(text.replace('_',' '),20)) \n",
    "\n",
    "# plot the matrices\n",
    "f,axs = plt.subplots(1,len(features))\n",
    "for i,feature in enumerate(features):\n",
    "    axs[i].imshow(feature.matrix,cmap=plt.cm.viridis)\n",
    "    axs[i].set_title(titleformat(feature.src_name),size=8)\n",
    "f.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
