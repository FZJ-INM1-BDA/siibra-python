{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from nilearn import plotting,image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#import matplotlib as mpl\n",
    "#mpl.rcParams['figure.dpi']= 200  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Setup brainscapes\n",
    "\n",
    "### Set a EBRAINS Knowledge Graph access token\n",
    "\n",
    "Brainscapes retrieves some data from the EBRAINS Knowledge Graph, which requires\n",
    "authentication. To do so, please follow these steps:\n",
    "\n",
    " 1. If you do not yet have an EBRAINS account, register [here](https://ebrains.eu/register). As you are reading this notebook in the EBRAINS collaboratory, this is most probably not necessary at this point.\n",
    " 2. Your EBRAINS account needs to be enabled for programmatic access to the EBRAINS Knowledge Graph to fetch metadata. This is formal step to acknowledge additional terms of use, and done quickly by emailing to the KG team. A link and template email to do so can be found right on top of the [Knowledge Graph developer page](https://kg.humanbrainproject.eu/develop.html).\n",
    " 3. Create an authentication token for EBRAINS by visiting\n",
    "[the EBRAINS authorization endpoint](https://nexus-iam.humanbrainproject.org/v0/oauth2/authorize). \n",
    " 4. Copy the token, and store it in the enviroment variable `HBP_AUTH_TOKEN` (just modify and execute the cell below accordingly).\n",
    "\n",
    "Note that as of now, you have to get a new token (steps 3. and 4.) approximately every day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "from os import environ\n",
    "webbrowser.open('https://nexus-iam.humanbrainproject.org/v0/oauth2/authorize')\n",
    "token = input(\"Enter your token here: \")\n",
    "environ['HBP_AUTH_TOKEN'] = token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brainscapes maintains a local cache of retrieved data. It will automatically choose the system default of your user account on most common operating systems, but you an also choose an explicit folder by setting the environment variable `BRAINSCAPES_CACHEDIR`. We are not using this here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir -p /tmp/brainscapescache\n",
    "#environ['BRAINSCAPES_CACHEDIR'] = \"/tmp/brainscapescache\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brainscapes as bs\n",
    "bs.logger.setLevel(\"INFO\") # show us some messages\n",
    "#bs.clear_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Choosing a parcellation\n",
    "\n",
    "We select the human atlas with cytoarchitectonic maps, and display maps in MNI152 and BigBrain space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas = bs.atlases.MULTILEVEL_HUMAN_ATLAS\n",
    "atlas.select_parcellation(bs.parcellations.JULICH_BRAIN_PROBABILISTIC_CYTOARCHITECTONIC_MAPS_V2_5)\n",
    "\n",
    "# in MNI 152 space\n",
    "icbm_mri = atlas.get_template(bs.spaces.MNI_152_ICBM_2009C_NONLINEAR_ASYMMETRIC)\n",
    "icbm_map = atlas.get_maps(bs.spaces.MNI_152_ICBM_2009C_NONLINEAR_ASYMMETRIC)\n",
    "for m in image.iter_img(icbm_map):\n",
    "    plotting.plot_stat_map(m)\n",
    "\n",
    "# bigbrain\n",
    "bigbrain_template = atlas.get_template(bs.spaces.BIG_BRAIN_HISTOLOGY,resolution=640)\n",
    "bigbrain_map = atlas.get_maps(bs.spaces.BIG_BRAIN_HISTOLOGY,resolution=640)\n",
    "for m in image.iter_img(bigbrain_map):\n",
    "    plotting.plot_stat_map(m,bg_img=bigbrain_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding and selection brain regions\n",
    "\n",
    "Brainscapes allows to search for regions through an atlas object in a number of ways. You can use text fragments of region names, region identifiers, or label indices of the parcellation maps. The library does its best to resolve them for you. Let's start with a simple text string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas.select_region(\"v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, V1 is subdivided into hemispheres. We can be more specific and select the left one. This is a leaf of the region hierarchy tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas.select_region(\"v1 left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to specifiy an element right away, we can use the 'regionnames' glossary stored in the atlas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas.select_region(atlas.regionnames.AREA_HOC1_V1_17_CALCS_LEFT_HEMISPHERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can also search for regions, even across all known parcellations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = atlas.find('ventral',all_parcellations=True)\n",
    "for m in matches:\n",
    "    print(\"{}: {} ({})\".format(m.parcellation,m.name,m.labelindex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regions which are labelleled in the parcellation map have a valid `labelindex` attached to them. We can also use this index to search and select regions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas.select_region(112)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brainscapes supports access to continuous maps for some parcellations. For the Julich-Brain, this translates to the actual probability maps of each area. Let's look at a probability map of the frontal pole in the ICBM space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas.select_region('fp2 right')\n",
    "pmap = atlas.selected_region.get_specific_map(bs.spaces.MNI_152_ICBM_2009C_NONLINEAR_ASYMMETRIC)\n",
    "plotting.plot_roi(pmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Extracting multimodal data features\n",
    "\n",
    "Brainscapes provides access to data features of different modalities using the `get_features` method, which accepts a feature modality and is sensitive to the selections configured in the atlas (parcellation, region). If not particular selection is made, `get_features` considers all brain regions of the current parcellation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract transmitter receptor densities\n",
    "\n",
    "Transmitter receptor density fingerprints are linked to brain regions by their name in the EBRAINS Knowledge Graph. Like any data feature, they are accessed using the `get_features` method of the atlas, which makes use of the current selection in the atlas. The `get_features` method knows from the specified data modality that the match is determined from the brain region identified. Receptor densities come as a nicely structured datatype. Amongst other things, they can visualize themselves in a plot.\n",
    "\n",
    "If we don't specify a particular selection, the atlas will return all available receptor density features linked to the parcellation map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas.clear_selection()\n",
    "features = atlas.get_features(\n",
    "    bs.modalities.ReceptorDistribution)\n",
    "print(\"Receptor density features found for the following regions:\")\n",
    "print(\"\\n\".join({f.region for f in features}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we select a region, the returned list is filtered accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas.select_region(\"v1\")\n",
    "features = atlas.get_features(\n",
    "    bs.modalities.ReceptorDistribution)\n",
    "for r in features:\n",
    "    fig = r.plot(r.region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Extract spatial properties of brain regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = atlas.regionprops(\n",
    "    bs.spaces.MNI_152_ICBM_2009C_NONLINEAR_ASYMMETRIC)\n",
    "for prop in props:\n",
    "    print(prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Extracting Gene Expressions from the Allen Atlas \n",
    "\n",
    "The atlas client can make calls to gene expression data from the Allen atlas and evaluate them in the ICBM space to find regional gene expression levels. It also has a list of available gene names for convenient selection. Gene expressions are linked to atlas regions by coordinates of their probes in MNI space. The `get_features` method detects this from the feature modality, and applies the mask of the regions that are currently selected in the atlas to filter the probes. We can visualize these filtered locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = atlas.get_features(\n",
    "    bs.modalities.GeneExpression, \n",
    "    gene=bs.features.gene_names.GABARAPL2)\n",
    "print(features[0])\n",
    "\n",
    "# plot\n",
    "all_coords = [tuple(g.location) for g in features]\n",
    "mask = atlas.get_mask(bs.spaces.MNI_152_ICBM_2009C_NONLINEAR_ASYMMETRIC)\n",
    "display = plotting.plot_roi(mask)\n",
    "display.add_markers(all_coords,marker_size=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Retrieving a connectivity matrix\n",
    "For brainscapes, a connectivity matrix is a data feature like the others below, and can be found using the same `get_features` function just by choosing another modality. Brainscapes knows from the modality type that this type of data does not match to the selected brain region in the atlas, but to the selected parcellation. Therefore, `get_features` return connectivity datasets that are defined for the selected parcellation. \n",
    "\n",
    "To learn about the nature of the provided connectivity, the `src_info` attribute provides a detailed description of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first four connectivity matrices available for the parcellation\n",
    "features = atlas.get_features(bs.modalities.ConnectivityMatrix)[:4]\n",
    "\n",
    "# format dataset names for use as figure titles\n",
    "from textwrap import wrap\n",
    "titleformat = lambda text : \"\\n\".join(wrap(text.replace('_',' '),20)) \n",
    "\n",
    "# plot the matrices\n",
    "f,axs = plt.subplots(1,len(features))\n",
    "for i,feature in enumerate(features):\n",
    "    axs[i].imshow(feature.matrix,cmap=plt.cm.viridis)\n",
    "    axs[i].set_title(titleformat(feature.src_name),size=8)\n",
    "f.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
